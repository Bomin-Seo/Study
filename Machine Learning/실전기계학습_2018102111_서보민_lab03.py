# -*- coding: utf-8 -*-
"""실전기계학습_2018102111_서보민_LAB03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RErPZ-aEwZrAktgPb_1JHA28QSfDQFxl

1. [프로그램 3-1 (c)]를 20개 샘플을 랜덤하게 선택하고 특징 값을 랜덤하게 5% 에서 변형해 테스
트 집합을 구성하도록 확장하시오. 이때 테스트 집합에 대한 예측을 수행하고 정확률을 측정하시
오.
"""

from sklearn import datasets, svm
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, cross_val_score
import random


d = datasets.load_iris()

x = d.data
y = d.target

x1, x_train, y1, y_train = train_test_split(x, y, test_size = 0.13, shuffle = True, stratify = y, random_state = 123)

print(x_train)
print("새로운 샘플의 부류는 ", y_train)
print()

x_test = x_train[:]

for i in range(len(x_train)):
  num = random.randint(95, 105)
  for j in range(4):
    x_test[i][j] = x_train[i][j] * num/100

s = svm.SVC(gamma = 0.1, C = 10)
s.fit(x_train, y_train)
y_test = s.predict(x_test)

new_index = []
for i in range(len(y_train)):
  if y_train[i] != y_test[i]:
    new_index.append(i)

print("new random sample index : ", new_index)
print(x_test)
print("변형된 샘플의 부류는 ",y_test)
print()
print("정확률은 : ", (len(y_train) - len(new_index))/len(y_train) * 100, "%" )

"""2. [프로그램 3-2]를 sepal length 특징을 제외하고 3차원 특징 공간을 그리도록 수정하고 데이터
분포에 대한 분석을 제시하시오.
"""

import plotly.express as px

df = px.data.iris()
fig = px.scatter_3d(df, x = 'sepal_width', y = 'petal_length', z = 'petal_width', color = 'species')
fig.show()

print("sepal width 축은 species간의 중복되는 범위가 많아 데이터 분별력이 낮습니다.")
print()
print("petal length축은 종 간의 분별력이 뛰어납니다. 다만 versicolor종과 virginica종의 몇 개의 샘플이 겹쳐 나타납니다")
print()
print("petal width축 또한 종간의 분별력이 뛰어납니다. 하지만 petal length보다 versicolor종과 virginica종간의 \n중복 범위가 많아 다수의 샘플이 겹쳐 나타납니다. ")

"""3. [프로그램 3-3 (a)]가 0~9부류의 샘플을 하나씩 랜덤하게 뽑아서 그리도록 확장하시오. """

digit = datasets.load_digits()
x = digit.data
y = digit.target
globals()['values{}'.format(i)] = [j for j in range(len(y)) if i == y[j]]

for i in range(10):
  globals()['values{}'.format(i)] = [j for j in range(len(y)) if i == y[j]]
  print("digit dataset 중에서 ", i, "이 있는 index : ", globals()['values{}'.format(i)])
  index = random.choice(globals()['values{}'.format(i)])
  print(i,"이 들어간 index 중 하나 선택 : ", index)
  plt.figure(figsize =(5,5))
  plt.imshow(digit.images[index],cmap=plt.cm.gray_r,interpolation = 'nearest')
  plt.show()
  print("이 숫자는", digit.target[index], "입니다.")
  print()

"""4. [프로그램 3-6]이 k를 5, 6, …, 10으로 변화시키며 k-겹 교차 검증을 수행하도록 확장하시오"""

s = svm.SVC(gamma = 0.001)
for i in range(5,11):
  print(i,"겹 교차검증")
  accuracies = cross_val_score(s, digit.data, digit.target, cv = i)
  print(accuracies)
  print("정확도(평균)=%0.3f, 표준편차=%0.3f"%(accuracies.mean()*100, accuracies.std()))
  print()

"""5. [프로그램 3-1]이 SVM뿐만 아니라 결정 트리 모델까지 적용하도록 확장하시오. 이때 훈련 집합
을 테스트 집합으로 간주해 SVM과 결정 트리의 정확률을 측정하고 비교하시오. (정확률 구현은
프로그램 3-4를 참고하시오.)
"""

from sklearn.tree import DecisionTreeClassifier

s = svm.SVC(gamma = 0.1, C = 10)
s.fit(d.data, d.target)
res = s.predict(d.data)
correct = [i for i in range(len(res)) if res[i] == d.target[i]]
accuracy = len(correct)/len(res)
print("SVM 사용했을 때 정확률 = ", accuracy*100,"%")

dtc = DecisionTreeClassifier(random_state = 123)
dtc.fit(d.data, d.target)
res2 = dtc.predict(d.data)
correct2 = [i for i in range(len(res)) if res2[i] == d.target[i]]
accuracy2 = len(correct2)/len(res2)
print("Random Forest 사용했을 때 정확률 = ", accuracy2*100,"%")