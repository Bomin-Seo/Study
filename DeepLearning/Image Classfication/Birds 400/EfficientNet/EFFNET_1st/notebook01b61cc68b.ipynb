{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport sys\nimport os\nimport time\nimport random \nimport pandas as pd\nimport torch\nfrom torch import nn, cuda, optim\nfrom torchvision import models,transforms,datasets\nfrom torch.utils.data import DataLoader,random_split\nfrom PIL import Image\nimport seaborn as sns\nimport torch.nn.functional as F\nimport shutil\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-02T02:28:08.546260Z","iopub.execute_input":"2022-06-02T02:28:08.546711Z","iopub.status.idle":"2022-06-02T02:28:11.006352Z","shell.execute_reply.started":"2022-06-02T02:28:08.546632Z","shell.execute_reply":"2022-06-02T02:28:11.005466Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/bird-data/Bird/train'\nclasses = []\nimg_per_class = []\n# for folder in os.listdir(data_dir+'consolidated'):/\nfor folder in os.listdir(data_dir):    \n    classes.append(folder)\n    img_per_class.append(len(os.listdir(f'{data_dir}/{folder}')))\nnum_classes = len(classes)\ndf = pd.DataFrame({'Classes':classes, 'Examples':img_per_class})\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:11.008910Z","iopub.execute_input":"2022-06-02T02:28:11.009795Z","iopub.status.idle":"2022-06-02T02:28:26.506256Z","shell.execute_reply.started":"2022-06-02T02:28:11.009746Z","shell.execute_reply":"2022-06-02T02:28:26.505440Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([transforms.RandomRotation(45),transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\nval_transform = transforms.Compose([transforms.RandomRotation(45),transforms.RandomHorizontalFlip(),\n                                    transforms.RandomVerticalFlip(),transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:26.508164Z","iopub.execute_input":"2022-06-02T02:28:26.508589Z","iopub.status.idle":"2022-06-02T02:28:26.515720Z","shell.execute_reply.started":"2022-06-02T02:28:26.508548Z","shell.execute_reply":"2022-06-02T02:28:26.514797Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    r\"\"\"Computes and stores the average and current value\n    \"\"\"\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, *meters, prefix=\"\"):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def print(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\t'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n\n\ndef accuracy(output, target, topk=(1,)):\n    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n    \"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        # _, pred = output.topk(maxk, 1, True, True)\n        # pred = pred.t()\n        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n        _, idx = output.sort(descending=True)\n        pred = idx[:,:maxk]\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:26.517102Z","iopub.execute_input":"2022-06-02T02:28:26.517693Z","iopub.status.idle":"2022-06-02T02:28:26.535254Z","shell.execute_reply.started":"2022-06-02T02:28:26.517656Z","shell.execute_reply":"2022-06-02T02:28:26.534376Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data = datasets.ImageFolder(data_dir)\ntrain_size = int(len(data)*0.95)\nval_size = int((len(data)-train_size))\ntrain_data,val_data = random_split(data,[train_size,val_size])\ntorch.manual_seed(3334)\nprint(f'train size: {len(train_data)}\\nval size: {len(val_data)}')\n\ntrain_data.dataset.transform = train_transform\nval_data.dataset.transform = val_transform\nbatch_size = 16\ntrain_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\nval_loader = DataLoader(val_data,batch_size=batch_size,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:26.538900Z","iopub.execute_input":"2022-06-02T02:28:26.539594Z","iopub.status.idle":"2022-06-02T02:28:26.963612Z","shell.execute_reply.started":"2022-06-02T02:28:26.539561Z","shell.execute_reply":"2022-06-02T02:28:26.962727Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"%cd '../input/efficientnet/EfficientNets-PyTorch-master'","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:26.964882Z","iopub.execute_input":"2022-06-02T02:28:26.965394Z","iopub.status.idle":"2022-06-02T02:28:26.973965Z","shell.execute_reply.started":"2022-06-02T02:28:26.965355Z","shell.execute_reply":"2022-06-02T02:28:26.972898Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import math\nfrom models.layers import conv_bn_act\nfrom models.layers import SamePadConv2d\nfrom models.layers import Flatten\nfrom models.layers import SEModule\nfrom models.layers import DropConnect","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:26.976232Z","iopub.execute_input":"2022-06-02T02:28:26.976806Z","iopub.status.idle":"2022-06-02T02:28:26.997473Z","shell.execute_reply.started":"2022-06-02T02:28:26.976763Z","shell.execute_reply":"2022-06-02T02:28:26.996750Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%cd '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:26.998764Z","iopub.execute_input":"2022-06-02T02:28:26.999100Z","iopub.status.idle":"2022-06-02T02:28:27.005541Z","shell.execute_reply.started":"2022-06-02T02:28:26.999066Z","shell.execute_reply":"2022-06-02T02:28:27.004649Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class MBConv(nn.Module):\n    def __init__(self, in_, out_, expand,\n                 kernel_size, stride, skip,\n                 se_ratio, dc_ratio=0.2):\n        super().__init__()\n        mid_ = in_ * expand\n        self.expand_conv = conv_bn_act(in_, mid_, kernel_size=1, bias=False) if expand != 1 else nn.Identity()\n\n        self.depth_wise_conv = conv_bn_act(mid_, mid_,\n                                           kernel_size=kernel_size, stride=stride,\n                                           groups=mid_, bias=False)\n\n        self.se = SEModule(mid_, int(in_ * se_ratio)) if se_ratio > 0 else nn.Identity()\n\n        self.project_conv = nn.Sequential(\n            SamePadConv2d(mid_, out_, kernel_size=1, stride=1, bias=False),\n            nn.BatchNorm2d(out_, 1e-3, 0.01)\n        )\n\n        # if _block_args.id_skip:\n        # and all(s == 1 for s in self._block_args.strides)\n        # and self._block_args.input_filters == self._block_args.output_filters:\n        self.skip = skip and (stride == 1) and (in_ == out_)\n\n        # DropConnect\n        # self.dropconnect = DropConnect(dc_ratio) if dc_ratio > 0 else nn.Identity()\n        # Original TF Repo not using drop_rate\n        # https://github.com/tensorflow/tpu/blob/05f7b15cdf0ae36bac84beb4aef0a09983ce8f66/models/official/efficientnet/efficientnet_model.py#L408\n        self.dropconnect = nn.Identity()\n\n    def forward(self, inputs):\n        expand = self.expand_conv(inputs)\n        x = self.depth_wise_conv(expand)\n        x = self.se(x)\n        x = self.project_conv(x)\n        if self.skip:\n            x = self.dropconnect(x)\n            x = x + inputs\n        return x\n\n\nclass MBBlock(nn.Module):\n    def __init__(self, in_, out_, expand, kernel, stride, num_repeat, skip, se_ratio, drop_connect_ratio=0.2):\n        super().__init__()\n        layers = [MBConv(in_, out_, expand, kernel, stride, skip, se_ratio, drop_connect_ratio)]\n        for i in range(1, num_repeat):\n            layers.append(MBConv(out_, out_, expand, kernel, 1, skip, se_ratio, drop_connect_ratio))\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.layers(x)\n\n\nclass EfficientNet(nn.Module):\n    def __init__(self, width_coeff, depth_coeff,\n                 depth_div=8, min_depth=None,\n                 dropout_rate=0.2, drop_connect_rate=0.2,\n                 num_classes=400):\n        super().__init__()\n        min_depth = min_depth or depth_div\n        \n        def renew_ch(x):\n            if not width_coeff:\n                return x\n\n            x *= width_coeff\n            new_x = max(min_depth, int(x + depth_div / 2) // depth_div * depth_div)\n            if new_x < 0.9 * x:\n                new_x += depth_div\n            return int(new_x)\n\n        def renew_repeat(x):\n            return int(math.ceil(x * depth_coeff))\n\n        self.stem = conv_bn_act(3, renew_ch(32), kernel_size=3, stride=2, bias=False)\n        \n        self.blocks = nn.Sequential(\n            #       input channel  output    expand  k  s                   skip  se\n            MBBlock(renew_ch(32), renew_ch(16), 1, 3, 1, renew_repeat(1), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(16), renew_ch(24), 6, 3, 2, renew_repeat(2), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(24), renew_ch(40), 6, 5, 2, renew_repeat(2), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(40), renew_ch(80), 6, 3, 2, renew_repeat(3), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(80), renew_ch(112), 6, 5, 1, renew_repeat(3), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(112), renew_ch(192), 6, 5, 2, renew_repeat(4), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(192), renew_ch(320), 6, 3, 1, renew_repeat(1), True, 0.25, drop_connect_rate)\n        )\n\n        self.head = nn.Sequential(\n            *conv_bn_act(renew_ch(320), renew_ch(1280), kernel_size=1, bias=False),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Dropout2d(dropout_rate, True) if dropout_rate > 0 else nn.Identity(),\n            Flatten(),\n            nn.Linear(renew_ch(1280), num_classes)\n        )\n\n        self.init_weights()\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, SamePadConv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n            elif isinstance(m, nn.Linear):\n                init_range = 1.0 / math.sqrt(m.weight.shape[1])\n                nn.init.uniform_(m.weight, -init_range, init_range)\n\n    def forward(self, inputs):\n        stem = self.stem(inputs)\n        x = self.blocks(stem)\n        head = self.head(x)\n        return head","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:27.007229Z","iopub.execute_input":"2022-06-02T02:28:27.008006Z","iopub.status.idle":"2022-06-02T02:28:27.037249Z","shell.execute_reply.started":"2022-06-02T02:28:27.007969Z","shell.execute_reply":"2022-06-02T02:28:27.036294Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = EfficientNet(1, 1, num_classes=400)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:27.038790Z","iopub.execute_input":"2022-06-02T02:28:27.039449Z","iopub.status.idle":"2022-06-02T02:28:27.152768Z","shell.execute_reply.started":"2022-06-02T02:28:27.039402Z","shell.execute_reply":"2022-06-02T02:28:27.151941Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pytorch_total_params = sum(p.numel() for p in model.parameters())\nprint(f\"Number of parameters: {pytorch_total_params}\")\nif int(pytorch_total_params) > 5000000:\n    print('Your model has the number of parameters more than 5 millions..')\n    sys.exit()\n    \ndevice = torch.device('cuda:0' if cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:31.262450Z","iopub.execute_input":"2022-06-02T02:28:31.263095Z","iopub.status.idle":"2022-06-02T02:28:33.911368Z","shell.execute_reply.started":"2022-06-02T02:28:31.263062Z","shell.execute_reply":"2022-06-02T02:28:33.910199Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=0.0005)\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones = [20, 40, 45], gamma = 0.5)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:33.913143Z","iopub.execute_input":"2022-06-02T02:28:33.913527Z","iopub.status.idle":"2022-06-02T02:28:33.923840Z","shell.execute_reply.started":"2022-06-02T02:28:33.913484Z","shell.execute_reply":"2022-06-02T02:28:33.922570Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def fit(model,criterion,optimizer,num_epochs=10):\n    print_freq = 100\n    start = time.time()\n    best_model = model.state_dict()\n    best_acc = 0\n    train_loss_over_time = []\n    val_loss_over_time = []\n    train_acc_over_time = []\n    val_acc_over_time = []\n\n\n    # each epoch has a training and validation phase\n    for epoch in range(num_epochs):\n        \n        print(\"\\n----- epoch: {}, lr: {} -----\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n        batch_time = AverageMeter('Time', ':6.3f')\n        acc = AverageMeter('Accuracy', ':.4e')\n        progress = ProgressMeter(len(train_loader), batch_time, acc, prefix=\"Epoch: [{}]\".format(epoch))\n\n        for phase in ['train','val']:\n            \n            if phase == 'train':\n                data_loader = train_loader\n                model.train()                    # set the model to train mode\n                end = time.time()\n\n            else:\n                data_loader = val_loader\n                model.eval()                    # set the model to evaluate mode\n                end = time.time()\n            \n                \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            # iterate over the data\n            for i,(inputs,labels) in enumerate(data_loader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _,pred = torch.max(outputs,dim=1)\n                    loss = criterion(outputs,labels)\n                    \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                \n                # calculating the loss and accuracy\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(pred == labels.data)\n\n                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n                acc.update(epoch_acc.item(), inputs.size(0))\n                \n                if phase == 'train':                          \n                    batch_time.update(time.time() - end)\n                    end = time.time()\n\n                    if i % print_freq == 0:\n                        progress.print(i)  \n\n            if phase == 'train':\n\n                epoch_loss = running_loss/len(train_data)\n                train_loss_over_time.append(epoch_loss)\n                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n                train_acc_over_time.append(epoch_acc)\n\n\n            else:\n                epoch_loss = running_loss/len(val_data)\n                val_loss_over_time.append(epoch_loss)\n                epoch_acc = (running_corrects.double()/len(val_data)).cpu().numpy()\n                val_acc_over_time.append(epoch_acc)\n          \n\n            print(f'{phase} loss: {epoch_loss:.3f}, acc: {epoch_acc:.3f}')\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                torch.save(model.state_dict(), 'model_best.pt')\n            \n            torch.save(model.state_dict(),'model_latest.pt')\n            \n        scheduler.step()\n        print('-'*60)\n    print('\\n') \n    elapsed_time = time.time() - start\n    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n    print(f'best accuracy: {best_acc:.3f}')\n\n\n    # load best model weights\n    model.load_state_dict(best_model)\n    loss = {'train':train_loss_over_time, 'val':val_loss_over_time}\n    acc = {'train':train_acc_over_time, 'val':val_acc_over_time}\n\n    return model,loss, acc","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:33.925570Z","iopub.execute_input":"2022-06-02T02:28:33.926245Z","iopub.status.idle":"2022-06-02T02:28:33.950200Z","shell.execute_reply.started":"2022-06-02T02:28:33.926200Z","shell.execute_reply":"2022-06-02T02:28:33.949128Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nepochs = 50\nhistory, loss, acc = fit(model, criterion, optimizer, num_epochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T02:28:33.952612Z","iopub.execute_input":"2022-06-02T02:28:33.953344Z","iopub.status.idle":"2022-06-02T09:04:27.001047Z","shell.execute_reply.started":"2022-06-02T02:28:33.953299Z","shell.execute_reply":"2022-06-02T09:04:27.000124Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_loss = loss['train']\nval_loss = loss['val']\ntrain_acc = acc['train']\nval_acc = acc['val']\n\nepochs_range = range(epochs)\nplt.figure(figsize=(20,10))\n\nplt.subplot(1,2,1)\nplt.ylim(0,10)\nplt.xlim(0,50)\nplt.plot(epochs_range, train_loss, label='train_loss')\nplt.plot(epochs_range, val_loss, label='val_loss')\nplt.legend(loc=0)\nplt.title('Loss')\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, train_acc ,label='train_acc')\nplt.plot(epochs_range, val_acc, label='val_acc')\nplt.legend(loc=0)\nplt.ylim(0,1)\nplt.xlim(0,50)\nplt.title('Accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:17:55.597731Z","iopub.execute_input":"2022-06-02T09:17:55.598448Z","iopub.status.idle":"2022-06-02T09:17:55.923129Z","shell.execute_reply.started":"2022-06-02T09:17:55.598410Z","shell.execute_reply":"2022-06-02T09:17:55.922390Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"seed = 0\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\ntorch.manual_seed(3334)\ntest_transform = transforms.Compose([transforms.RandomRotation(45),transforms.RandomHorizontalFlip(),\n                                    transforms.RandomVerticalFlip(),transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\n\n# splitting the data into train/validation/test sets\ntest_data_dir = '../input/bird-data/Bird/test'\n_data = datasets.ImageFolder(test_data_dir)\ntest1_size = int(len(_data)*1)\ntest2_size = int((len(_data)-test1_size))\ntest_data, test2_data = torch.utils.data.random_split(_data,[test1_size, test2_size])\ntorch.manual_seed(3334)\n\nprint(f'test size: {len(test_data)}')\n\ntest_data.dataset.transform = test_transform\nbatch_size = 16\ntest_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False)\nprint(test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:31:07.351143Z","iopub.execute_input":"2022-06-02T09:31:07.351508Z","iopub.status.idle":"2022-06-02T09:31:07.670379Z","shell.execute_reply.started":"2022-06-02T09:31:07.351467Z","shell.execute_reply":"2022-06-02T09:31:07.668805Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import itertools\n# testing how good the model is\ndef evaluate(model,criterion):\n    model.eval()       # setting the model to evaluate mode\n    preds = []\n    Category = []\n    \n    test_model = EfficientNet(1, 1, num_classes=400).cuda()\n    #저장경로는 변경하셔도 됩니다.\n    test_model.load_state_dict(torch.load('./model_best.pt'))\n    for inputs, label_ in test_loader:\n        inputs = inputs.to(device)\n        labels = label_.to(device)\n        # predicting\n        with torch.no_grad():\n\n            outputs = test_model(inputs)\n            _,pred = torch.max(outputs,dim=1)\n            preds.append(pred)\n\n    category = [t.cpu().numpy() for t in preds]\n    \n    t_category = list(itertools.chain(*category))\n   \n    Id = list(range(0, len(t_category)))\n\n    prediction = {\n      'Id': Id,\n      'Category': t_category \n    }\n\n    prediction_df = pd.DataFrame(prediction, columns=['Id','Category'])\n    #저장경로는 변경하셔도 됩니다.\n    prediction_df.to_csv('./prediction2.csv', index=False)\n\n    print('Done!!')\n        \n    return preds\n\n# testing the model\npredictions = evaluate(model, criterion)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T09:31:14.974143Z","iopub.execute_input":"2022-06-02T09:31:14.974505Z","iopub.status.idle":"2022-06-02T09:31:23.223584Z","shell.execute_reply.started":"2022-06-02T09:31:14.974462Z","shell.execute_reply":"2022-06-02T09:31:23.221946Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}