{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport sys\nimport os\nimport time\nimport random \nimport pandas as pd\nimport torch\nfrom torch import nn, cuda, optim\nfrom torchvision import models,transforms,datasets\nfrom torch.utils.data import DataLoader,random_split\nfrom PIL import Image\nimport seaborn as sns\nimport torch.nn.functional as F\nimport shutil\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-08T08:46:36.248539Z","iopub.execute_input":"2022-06-08T08:46:36.249605Z","iopub.status.idle":"2022-06-08T08:46:40.674441Z","shell.execute_reply.started":"2022-06-08T08:46:36.249493Z","shell.execute_reply":"2022-06-08T08:46:40.672814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/birddata/train'\nclasses = []\nimg_per_class = []\nfor folder in os.listdir(data_dir):    \n    classes.append(folder)\n    img_per_class.append(len(os.listdir(f'{data_dir}/{folder}')))\nnum_classes = len(classes)\ndf = pd.DataFrame({'Classes':classes, 'Examples':img_per_class})\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:46:53.765296Z","iopub.execute_input":"2022-06-08T08:46:53.76644Z","iopub.status.idle":"2022-06-08T08:47:13.982377Z","shell.execute_reply.started":"2022-06-08T08:46:53.766398Z","shell.execute_reply":"2022-06-08T08:47:13.981243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([transforms.RandomRotation(15),transforms.RandomHorizontalFlip(),\n                                      transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\nval_transform = transforms.Compose([transforms.RandomRotation(15),transforms.RandomHorizontalFlip(),\n                                      transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:15.412599Z","iopub.execute_input":"2022-06-08T08:47:15.413061Z","iopub.status.idle":"2022-06-08T08:47:15.423325Z","shell.execute_reply.started":"2022-06-08T08:47:15.413028Z","shell.execute_reply":"2022-06-08T08:47:15.421138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    r\"\"\"Computes and stores the average and current value\n    \"\"\"\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, *meters, prefix=\"\"):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def print(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\t'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n\n\ndef accuracy(output, target, topk=(1,)):\n    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n    \"\"\"\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        # _, pred = output.topk(maxk, 1, True, True)\n        # pred = pred.t()\n        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n        _, idx = output.sort(descending=True)\n        pred = idx[:,:maxk]\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:16.135355Z","iopub.execute_input":"2022-06-08T08:47:16.135883Z","iopub.status.idle":"2022-06-08T08:47:16.156603Z","shell.execute_reply.started":"2022-06-08T08:47:16.135852Z","shell.execute_reply":"2022-06-08T08:47:16.155404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = datasets.ImageFolder(data_dir)\ntrain_size = int(len(data)*0.95)\nval_size = int((len(data)-train_size))\ntrain_data,val_data = random_split(data,[train_size,val_size])\ntorch.manual_seed(3334)\nprint(f'train size: {len(train_data)}\\nval size: {len(val_data)}')\n\ntrain_data.dataset.transform = train_transform\nval_data.dataset.transform = val_transform\nbatch_size = 16\ntrain_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True, num_workers = 2)\nval_loader = DataLoader(val_data,batch_size=batch_size,shuffle=False, num_workers = 2)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:18.542047Z","iopub.execute_input":"2022-06-08T08:47:18.542788Z","iopub.status.idle":"2022-06-08T08:47:19.046991Z","shell.execute_reply.started":"2022-06-08T08:47:18.542745Z","shell.execute_reply":"2022-06-08T08:47:19.045264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd '../input/efficientnet/EfficientNets-PyTorch-master'","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:19.586015Z","iopub.execute_input":"2022-06-08T08:47:19.586921Z","iopub.status.idle":"2022-06-08T08:47:19.597502Z","shell.execute_reply.started":"2022-06-08T08:47:19.586887Z","shell.execute_reply":"2022-06-08T08:47:19.596187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom models.layers import conv_bn_act\nfrom models.layers import SamePadConv2d\nfrom models.layers import Flatten\nfrom models.layers import SEModule\nfrom models.layers import DropConnect","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:20.945795Z","iopub.execute_input":"2022-06-08T08:47:20.946902Z","iopub.status.idle":"2022-06-08T08:47:20.975592Z","shell.execute_reply.started":"2022-06-08T08:47:20.946868Z","shell.execute_reply":"2022-06-08T08:47:20.974459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:21.647898Z","iopub.execute_input":"2022-06-08T08:47:21.6491Z","iopub.status.idle":"2022-06-08T08:47:21.656971Z","shell.execute_reply.started":"2022-06-08T08:47:21.649057Z","shell.execute_reply":"2022-06-08T08:47:21.655831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MBConv(nn.Module):\n    def __init__(self, in_, out_, expand,\n                 kernel_size, stride, skip,\n                 se_ratio, dc_ratio=0.2):\n        super().__init__()\n        mid_ = in_ * expand\n        self.expand_conv = conv_bn_act(in_, mid_, kernel_size=1, bias=False) if expand != 1 else nn.Identity()\n\n        self.depth_wise_conv = conv_bn_act(mid_, mid_,\n                                           kernel_size=kernel_size, stride=stride,\n                                           groups=mid_, bias=False)\n\n        self.se = SEModule(mid_, int(in_ * se_ratio)) if se_ratio > 0 else nn.Identity()\n\n        self.project_conv = nn.Sequential(\n            SamePadConv2d(mid_, out_, kernel_size=1, stride=1, bias=False),\n            nn.BatchNorm2d(out_, 1e-3, 0.01)\n        )\n\n        # if _block_args.id_skip:\n        # and all(s == 1 for s in self._block_args.strides)\n        # and self._block_args.input_filters == self._block_args.output_filters:\n        self.skip = skip and (stride == 1) and (in_ == out_)\n\n        # DropConnect\n        # self.dropconnect = DropConnect(dc_ratio) if dc_ratio > 0 else nn.Identity()\n        # Original TF Repo not using drop_rate\n        # https://github.com/tensorflow/tpu/blob/05f7b15cdf0ae36bac84beb4aef0a09983ce8f66/models/official/efficientnet/efficientnet_model.py#L408\n        self.dropconnect = nn.Identity()\n\n    def forward(self, inputs):\n        expand = self.expand_conv(inputs)\n        x = self.depth_wise_conv(expand)\n        x = self.se(x)\n        x = self.project_conv(x)\n        if self.skip:\n            x = self.dropconnect(x)\n            x = x + inputs\n        return x\n\n\nclass MBBlock(nn.Module):\n    def __init__(self, in_, out_, expand, kernel, stride, num_repeat, skip, se_ratio, drop_connect_ratio=0.2):\n        super().__init__()\n        layers = [MBConv(in_, out_, expand, kernel, stride, skip, se_ratio, drop_connect_ratio)]\n        for i in range(1, num_repeat):\n            layers.append(MBConv(out_, out_, expand, kernel, 1, skip, se_ratio, drop_connect_ratio))\n        self.layers = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.layers(x)\n\n\nclass EfficientNet(nn.Module):\n    def __init__(self, width_coeff, depth_coeff,\n                 depth_div=8, min_depth=None,\n                 dropout_rate=0.2, drop_connect_rate=0.2,\n                 num_classes=400):\n        super().__init__()\n        min_depth = min_depth or depth_div\n        \n        def renew_ch(x):\n            if not width_coeff:\n                return x\n\n            x *= width_coeff\n            new_x = max(min_depth, int(x + depth_div / 2) // depth_div * depth_div)\n            if new_x < 0.9 * x:\n                new_x += depth_div\n            return int(new_x)\n\n        def renew_repeat(x):\n            return int(math.ceil(x * depth_coeff))\n\n        self.stem = conv_bn_act(3, renew_ch(32), kernel_size=3, stride=2, bias=False)\n        \n        self.blocks = nn.Sequential(\n            #       input channel  output    expand  k  s                   skip  se\n            MBBlock(renew_ch(32), renew_ch(16), 1, 3, 1, renew_repeat(1), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(16), renew_ch(24), 6, 3, 2, renew_repeat(2), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(24), renew_ch(40), 6, 5, 2, renew_repeat(2), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(40), renew_ch(80), 6, 3, 2, renew_repeat(3), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(80), renew_ch(112), 6, 5, 1, renew_repeat(3), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(112), renew_ch(192), 6, 5, 2, renew_repeat(4), True, 0.25, drop_connect_rate),\n            MBBlock(renew_ch(192), renew_ch(320), 6, 3, 1, renew_repeat(1), True, 0.25, drop_connect_rate)\n        )\n\n        self.head = nn.Sequential(\n            *conv_bn_act(renew_ch(320), renew_ch(1280), kernel_size=1, bias=False),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Dropout2d(dropout_rate, True) if dropout_rate > 0 else nn.Identity(),\n            Flatten(),\n            nn.Linear(renew_ch(1280), num_classes)\n        )\n\n        self.init_weights()\n\n    def init_weights(self):\n        for m in self.modules():\n            if isinstance(m, SamePadConv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n            elif isinstance(m, nn.Linear):\n                init_range = 1.0 / math.sqrt(m.weight.shape[1])\n                nn.init.uniform_(m.weight, -init_range, init_range)\n\n    def forward(self, inputs):\n        stem = self.stem(inputs)\n        x = self.blocks(stem)\n        head = self.head(x)\n        return head","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:22.290995Z","iopub.execute_input":"2022-06-08T08:47:22.291831Z","iopub.status.idle":"2022-06-08T08:47:22.324448Z","shell.execute_reply.started":"2022-06-08T08:47:22.291765Z","shell.execute_reply":"2022-06-08T08:47:22.322902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = EfficientNet(1.06, 1, dropout_rate = 0.5, drop_connect_rate=0.5, num_classes=400)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:23.978495Z","iopub.execute_input":"2022-06-08T08:47:23.979745Z","iopub.status.idle":"2022-06-08T08:47:24.205095Z","shell.execute_reply.started":"2022-06-08T08:47:23.979693Z","shell.execute_reply":"2022-06-08T08:47:24.203693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pytorch_total_params = sum(p.numel() for p in model.parameters())\nprint(f\"Number of parameters: {pytorch_total_params}\")\nif int(pytorch_total_params) > 5000000:\n    print('Your model has the number of parameters more than 5 millions..')\n    sys.exit()\n    \ndevice = torch.device('cuda:0' if cuda.is_available() else 'cpu')\nmodel.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:24.677967Z","iopub.execute_input":"2022-06-08T08:47:24.679061Z","iopub.status.idle":"2022-06-08T08:47:28.168977Z","shell.execute_reply.started":"2022-06-08T08:47:24.679026Z","shell.execute_reply":"2022-06-08T08:47:28.167835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# optimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=0.0005)\n# optimizer = optim.NAdam(params, lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.005, momentum_decay=0.004)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.9, nesterov=True, weight_decay=0.0005)\n\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones = [20, 30, 35, 40, 43, 47], gamma = 0.5)\n# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 5, eta_min=0, last_epoch=- 1, verbose=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:30.567189Z","iopub.execute_input":"2022-06-08T08:47:30.568317Z","iopub.status.idle":"2022-06-08T08:47:30.579448Z","shell.execute_reply.started":"2022-06-08T08:47:30.568283Z","shell.execute_reply":"2022-06-08T08:47:30.578342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(model,criterion,optimizer,num_epochs=10):\n    print_freq = 200\n    start = time.time()\n    best_model = model.state_dict()\n    best_acc = 0\n    train_loss_over_time = []\n    val_loss_over_time = []\n    train_acc_over_time = []\n    val_acc_over_time = []\n\n\n    # each epoch has a training and validation phase\n    for epoch in range(num_epochs):\n        \n        print(\"\\n----- epoch: {}, lr: {} -----\".format(epoch, optimizer.param_groups[0][\"lr\"]))\n        batch_time = AverageMeter('Time', ':6.3f')\n        acc = AverageMeter('Accuracy', ':.4e')\n        progress = ProgressMeter(len(train_loader), batch_time, acc, prefix=\"Epoch: [{}]\".format(epoch))\n\n        for phase in ['train','val']:\n            \n            if phase == 'train':\n                data_loader = train_loader\n                model.train()                    # set the model to train mode\n                end = time.time()\n\n            else:\n                data_loader = val_loader\n                model.eval()                    # set the model to evaluate mode\n                end = time.time()\n            \n                \n            running_loss = 0.0\n            running_corrects = 0.0\n            \n            # iterate over the data\n            for i,(inputs,labels) in enumerate(data_loader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                \n                # zero the parameter gradients\n                optimizer.zero_grad()\n                \n                # forward\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _,pred = torch.max(outputs,dim=1)\n                    loss = criterion(outputs,labels)\n                    \n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                \n                # calculating the loss and accuracy\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(pred == labels.data)\n\n                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n                acc.update(epoch_acc.item(), inputs.size(0))\n                \n                if phase == 'train':                          \n                    batch_time.update(time.time() - end)\n                    end = time.time()\n\n                    if i % print_freq == 0:\n                        progress.print(i)  \n\n            if phase == 'train':\n\n                epoch_loss = running_loss/len(train_data)\n                train_loss_over_time.append(epoch_loss)\n                epoch_acc = (running_corrects.double()/len(train_data)).cpu().numpy()\n                train_acc_over_time.append(epoch_acc)\n\n\n            else:\n                epoch_loss = running_loss/len(val_data)\n                val_loss_over_time.append(epoch_loss)\n                epoch_acc = (running_corrects.double()/len(val_data)).cpu().numpy()\n                val_acc_over_time.append(epoch_acc)\n          \n\n            print(f'{phase} loss: {epoch_loss:.3f}, acc: {epoch_acc:.3f}')\n            \n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                torch.save(model.state_dict(), 'model_best.pt')\n            \n            torch.save(model.state_dict(),'model_latest.pt')\n            \n        scheduler.step()\n        print('-'*60)\n    print('\\n') \n    elapsed_time = time.time() - start\n    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n    print(f'best accuracy: {best_acc:.3f}')\n\n\n    # load best model weights\n    model.load_state_dict(best_model)\n    loss = {'train':train_loss_over_time, 'val':val_loss_over_time}\n    acc = {'train':train_acc_over_time, 'val':val_acc_over_time}\n\n    return model,loss, acc","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:31.229748Z","iopub.execute_input":"2022-06-08T08:47:31.230555Z","iopub.status.idle":"2022-06-08T08:47:31.256377Z","shell.execute_reply.started":"2022-06-08T08:47:31.230517Z","shell.execute_reply":"2022-06-08T08:47:31.255155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nepochs = 50\nhistory, loss, acc = fit(model, criterion, optimizer, num_epochs = epochs)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:47:31.854004Z","iopub.execute_input":"2022-06-08T08:47:31.854718Z","iopub.status.idle":"2022-06-08T08:47:38.178044Z","shell.execute_reply.started":"2022-06-08T08:47:31.854682Z","shell.execute_reply":"2022-06-08T08:47:38.174864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss = loss['train']\nval_loss = loss['val']\ntrain_acc = acc['train']\nval_acc = acc['val']\n\nepochs_range = range(epochs)\nplt.figure(figsize=(20,10))\n\nplt.subplot(1,2,1)\nplt.ylim(0,10)\nplt.xlim(0,50)\nplt.plot(epochs_range, train_loss, label='train_loss')\nplt.plot(epochs_range, val_loss, label='val_loss')\nplt.legend(loc=0)\nplt.title('Loss')\n\nplt.subplot(1,2,2)\nplt.plot(epochs_range, train_acc ,label='train_acc')\nplt.plot(epochs_range, val_acc, label='val_acc')\nplt.legend(loc=0)\nplt.ylim(0,1)\nplt.xlim(0,50)\nplt.title('Accuracy')","metadata":{"execution":{"iopub.status.busy":"2022-06-06T05:02:06.438268Z","iopub.execute_input":"2022-06-06T05:02:06.438886Z","iopub.status.idle":"2022-06-06T05:02:06.744632Z","shell.execute_reply.started":"2022-06-06T05:02:06.438848Z","shell.execute_reply":"2022-06-06T05:02:06.743906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 0\ntorch.manual_seed(seed)\nif cuda:\n    torch.cuda.manual_seed(seed)\n\ntorch.manual_seed(3334)\ntest_transform = transforms.Compose([transforms.RandomRotation(15),transforms.RandomHorizontalFlip(),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\n\n# splitting the data into train/validation/test sets\ntest_data_dir = '../input/birddata/test'\n_data = datasets.ImageFolder(test_data_dir)\ntest1_size = int(len(_data)*1)\ntest2_size = int((len(_data)-test1_size))\ntest_data, test2_data = torch.utils.data.random_split(_data,[test1_size, test2_size])\ntorch.manual_seed(3334)\n\nprint(f'test size: {len(test_data)}')\n\ntest_data.dataset.transform = test_transform\nbatch_size = 64\ntest_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False)\nprint(test_loader)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:37:15.753868Z","iopub.execute_input":"2022-06-08T08:37:15.754231Z","iopub.status.idle":"2022-06-08T08:37:18.437858Z","shell.execute_reply.started":"2022-06-08T08:37:15.754199Z","shell.execute_reply":"2022-06-08T08:37:18.437013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n# testing how good the model is\ndef evaluate(model,criterion):\n    model.eval()       # setting the model to evaluate mode\n    preds = []\n    Category = []\n    \n    test_model = EfficientNet(1.06, 1, dropout_rate = 0.18, drop_connect_rate=0.24, num_classes=400).cuda()\n    test_model.load_state_dict(torch.load('./model_best.pt'))\n    for inputs, label_ in test_loader:\n        inputs = inputs.to(device)\n        labels = label_.to(device)\n        # predicting\n        with torch.no_grad():\n\n            outputs = test_model(inputs)\n            _,pred = torch.max(outputs,dim=1)\n            preds.append(pred)\n\n    category = [t.cpu().numpy() for t in preds]\n    \n    t_category = list(itertools.chain(*category))\n   \n    Id = list(range(0, len(t_category)))\n\n    prediction = {\n      'Id': Id,\n      'Category': t_category \n    }\n\n    prediction_df = pd.DataFrame(prediction, columns=['Id','Category'])\n    #저장경로는 변경하셔도 됩니다.\n    prediction_df.to_csv('prediction.csv', index=False)\n\n    print('Done!!')\n        \n    return preds\n\n# testing the model\npredictions = evaluate(model, criterion)","metadata":{"execution":{"iopub.status.busy":"2022-06-08T08:43:36.977009Z","iopub.execute_input":"2022-06-08T08:43:36.97738Z","iopub.status.idle":"2022-06-08T08:43:44.805912Z","shell.execute_reply.started":"2022-06-08T08:43:36.97733Z","shell.execute_reply":"2022-06-08T08:43:44.804231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}